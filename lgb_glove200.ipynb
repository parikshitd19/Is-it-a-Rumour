{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score,precision_score,f1_score,precision_recall_fscore_support\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from helper_function import *\n",
    "from Tweet_Info_Obj import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm\n",
    "!pip nstall optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-disclosure",
   "metadata": {},
   "source": [
    "Train,Development and Test data is extracted from the respective files and preprocessed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets_corpus,train_tweet_id,=extract_data('project-data/train.data.jsonl')\n",
    "dev_tweets_corpus,dev_tweet_id,=extract_data('project-data/dev.data.jsonl')\n",
    "test_tweets_corpus,test_tweet_id,=extract_data('project-data/test.data.jsonl')\n",
    "\n",
    "train_data_label=get_labels('project-data/train.label.json',train_tweet_id)\n",
    "dev_data_label=get_labels('project-data/dev.label.json',dev_tweet_id)\n",
    "# Tweet text is preprocessed\n",
    "preprocess_train_tweet_corpous=preprocees_tweets(train_tweets_corpus)\n",
    "preprocess_test_tweet_corpous=preprocees_tweets(test_tweets_corpus)\n",
    "preprocess_dev_tweet_corpous=preprocees_tweets(dev_tweets_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-christianity",
   "metadata": {},
   "source": [
    "We are utlizing the GLoVe of dimension 200 to get a single representation of each tweet and reply group.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dimension=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict={}\n",
    "with open(\"glove/glove.twitter.27B.200d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tweet(tweet):\n",
    "    # separate punctuations\n",
    "    tweet = tweet.replace(\".\", \" . \") \\\n",
    "                 .replace(\",\", \" , \") \\\n",
    "                 .replace(\";\", \" ; \") \\\n",
    "                 .replace(\"?\", \" ? \")\\\n",
    "                 .replace(\"\\'\",\"\")\n",
    "    return tweet.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet2vec(tweet,embeddings_dict):\n",
    "    vector_sum = sum(embeddings_dict.get(w,np.zeros(vector_dimension)) for w in split_tweet(tweet))\n",
    "    return vector_sum\n",
    "\n",
    "def tweet_corpous_to_vector(corpous,embeddings_dict):\n",
    "    corp_vec=[]\n",
    "    for tweet_group in corpous:\n",
    "        tweet_vec_grp=[tweet2vec(tweet,embeddings_dict) for tweet in tweet_group]\n",
    "        corp_vec.append(tweet_vec_grp)\n",
    "    return corp_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweet_grp_vectors=tweet_corpous_to_vector(preprocess_train_tweet_corpous,embeddings_dict)\n",
    "test_tweet_grp_vectors=tweet_corpous_to_vector(preprocess_test_tweet_corpous,embeddings_dict)\n",
    "dev_tweet_grp_vectors=tweet_corpous_to_vector(preprocess_dev_tweet_corpous,embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group2single(group):\n",
    "    return sum(j for j in group)/len(group)\n",
    "\n",
    "def convert2single(dataset):\n",
    "    return [group2single(group) for group in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainX=convert2single(train_tweet_grp_vectors)\n",
    "TestX=convert2single(test_tweet_grp_vectors)\n",
    "DevX=convert2single(dev_tweet_grp_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainY=[0 if x=='non-rumour' else 1 for x in train_data_label]\n",
    "DevY=[0 if x=='non-rumour' else 1 for x in dev_data_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(y_true,y_pred):\n",
    "    print(f1_score(y_true,y_pred),precision_score(y_true,y_pred),recall_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-parking",
   "metadata": {},
   "source": [
    "Creating a model with a basic Random Forest model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=50, random_state=0)\n",
    "clf=clf.fit(TrainX,TrainY)\n",
    "y_pred=clf.predict(DevX)\n",
    "print_scores(DevY,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-pollution",
   "metadata": {},
   "source": [
    "Tuning the appropriate paramaters for a Light GBM model using Optuna.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat =y_hat = np.where(y_hat < 0.5, 0, 1)  \n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\":\"lgb_f1_score\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.01, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.01, 10.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 300),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.1, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.1, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 300),\n",
    "        \"learning_rate\":trial.suggest_float(\"learning_rate\", 0.001, 0.5),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 100, 500),\n",
    "        'num_iterations': trial.suggest_int('num_iterations', 400, 800),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 160000,160000),\n",
    "        'min_data_per_group':trial.suggest_int('min_data_per_group', 100,500)\n",
    "    }\n",
    "    \n",
    "    model=lgb.LGBMClassifier()\n",
    "    model=model.set_params(**param)\n",
    "    model=model.fit(TrainX,TrainY)\n",
    "    pred=model.predict(DevX)\n",
    "    f1 = f1_score(DevY,pred)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "param=study.best_trial.params\n",
    "param['metric']=\"lgb_f1_score\"\n",
    "param[\"objective\"]= \"binary\"\n",
    "param[\"verbosity\"]= -1\n",
    "param[\"boosting_type\"]=\"gbdt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=lgb.LGBMClassifier()\n",
    "model=model.set_params(**param)\n",
    "model=model.fit(TrainX,TrainY)\n",
    "pred=model.predict(DevX)\n",
    "print_scores(DevY,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'lgb_200glove.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=lgb.LGBMClassifier()\n",
    "model=model.set_params(**param)\n",
    "model=model.fit(TrainX+DevX,TrainY+DevY)\n",
    "y_pred=model.predict(TestX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict={}\n",
    "\n",
    "for i in range(len(test_tweet_id)):\n",
    "    if y_pred[i]==0:\n",
    "        output_dict[test_tweet_id[i]]='non-rumour'\n",
    "    else: \n",
    "        output_dict[test_tweet_id[i]]='rumour'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test-output.json', 'w') as f:\n",
    "    json.dump(output_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline=json.load(open('project-data/dev.baseline.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    if label == \"rumour\":\n",
    "        return 1\n",
    "    elif label == \"non-rumour\":\n",
    "        return 0\n",
    "    else:\n",
    "        raise Exception(\"label classes must be 'rumour' or 'non-rumour'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = [], []\n",
    "\n",
    "try:\n",
    "    for k, v in baseline.items():\n",
    "        if k in output_dict:\n",
    "            y_pred.append(convert_label(output_dict[k]))\n",
    "        else:\n",
    "            y_pred.append(int(not(bool(convert_label(v)))))\n",
    "        y_true.append(convert_label(v))\n",
    "\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, pos_label=1, average=\"binary\")\n",
    "except Exception as error:\n",
    "    print(\"Error:\", error)\n",
    "    raise SystemExit\n",
    "\n",
    "\n",
    "print(\"Performance on the rumour class:\")\n",
    "print(\"Precision =\", p)\n",
    "print(\"Recall    =\", r)\n",
    "print(\"F1        =\", f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
