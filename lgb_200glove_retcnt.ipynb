{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from helper_function import *\n",
    "from Tweet_Info_Obj import *\n",
    "from sklearn.metrics import recall_score,precision_score,f1_score,precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets_corpus,train_tweet_id,train_tweet_info=extract_data('project-data/train.data.jsonl')\n",
    "dev_tweets_corpus,dev_tweet_id,dev_tweet_info=extract_data('project-data/dev.data.jsonl')\n",
    "test_tweets_corpus,test_tweet_id,test_tweet_info=extract_data('project-data/test.data.jsonl')\n",
    "\n",
    "train_data_label=get_labels('project-data/train.label.json',train_tweet_id)\n",
    "dev_data_label=get_labels('project-data/dev.label.json',dev_tweet_id)\n",
    "\n",
    "preprocess_train_tweet_corpous=preprocees_tweets(train_tweets_corpus)\n",
    "preprocess_test_tweet_corpous=preprocees_tweets(test_tweets_corpus)\n",
    "preprocess_dev_tweet_corpous=preprocees_tweets(dev_tweets_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dimension=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict={}\n",
    "with open(\"glove/glove.twitter.27B.200d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tweet(tweet):\n",
    "    # separate punctuations\n",
    "    tweet = tweet.replace(\".\", \" . \") \\\n",
    "                 .replace(\",\", \" , \") \\\n",
    "                 .replace(\";\", \" ; \") \\\n",
    "                 .replace(\"?\", \" ? \")\\\n",
    "                 .replace(\"\\'\",\"\")\n",
    "    return tweet.split()\n",
    "\n",
    "def tweet2vec(tweet,embeddings_dict):\n",
    "    vector_sum = sum(embeddings_dict.get(w,np.zeros(vector_dimension)) for w in split_tweet(tweet))\n",
    "    return vector_sum\n",
    "\n",
    "def tweet_corpous_to_vector(corpous,embeddings_dict):\n",
    "    corp_vec=[]\n",
    "    for tweet_group in corpous:\n",
    "        tweet_vec_grp=[tweet2vec(tweet,embeddings_dict) for tweet in tweet_group]\n",
    "        corp_vec.append(tweet_vec_grp)\n",
    "    return corp_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweet_grp_vectors=tweet_corpous_to_vector(preprocess_train_tweet_corpous,embeddings_dict)\n",
    "test_tweet_grp_vectors=tweet_corpous_to_vector(preprocess_test_tweet_corpous,embeddings_dict)\n",
    "dev_tweet_grp_vectors=tweet_corpous_to_vector(preprocess_dev_tweet_corpous,embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group2single(group,tweet_info):\n",
    "    sumvec=np.zeros(group[0].shape)\n",
    "    retweet_count_sum=sum([t.retweet_count for t in tweet_info])\n",
    "    for i in range(len(group)):\n",
    "        sumvec+=group[i]*((tweet_info[i].retweet_count+1)/(retweet_count_sum+len(group)))\n",
    "    return sumvec\n",
    "\n",
    "def convert2single(dataset,tweet_info_corp):\n",
    "    return [group2single(dataset[i],tweet_info_corp[i]) for i in range(len(dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainX=convert2single(train_tweet_grp_vectors,train_tweet_info)\n",
    "TestX=convert2single(test_tweet_grp_vectors,test_tweet_info)\n",
    "DevX=convert2single(dev_tweet_grp_vectors,dev_tweet_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainY=[0 if x=='non-rumour' else 1 for x in train_data_label]\n",
    "DevY=[0 if x=='non-rumour' else 1 for x in dev_data_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(y_true,y_pred):\n",
    "    print(f1_score(y_true,y_pred),precision_score(y_true,y_pred),recall_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat =y_hat = np.where(y_hat < 0.5, 0, 1)  \n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\":\"lgb_f1_score\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.01, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.01, 10.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 300),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.1, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.1, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 300),\n",
    "        \"learning_rate\":trial.suggest_float(\"learning_rate\", 0.001, 0.5),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 100, 500),\n",
    "        'num_iterations': trial.suggest_int('num_iterations', 400, 800),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 160000,160000),\n",
    "        'min_data_per_group':trial.suggest_int('min_data_per_group', 100,500)\n",
    "    }\n",
    "    \n",
    "    model=lgb.LGBMClassifier()\n",
    "    model=model.set_params(**param)\n",
    "    model=model.fit(TrainX,TrainY)\n",
    "    pred=model.predict(DevX)\n",
    "    f1 = f1_score(DevY,pred)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "param=study.best_trial.params\n",
    "param['metric']=\"lgb_f1_score\"\n",
    "param[\"objective\"]= \"binary\"\n",
    "param[\"verbosity\"]= -1\n",
    "param[\"boosting_type\"]=\"gbdt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=lgb.LGBMClassifier()\n",
    "model=model.set_params(**param)\n",
    "model=model.fit(TrainX,TrainY)\n",
    "pred=model.predict(DevX)\n",
    "print_scores(DevY,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'lgb_200glove_retweetcountWeight.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group2single(group,tweet_info):\n",
    "    sumvec=np.zeros(group[0].shape)\n",
    "    retweet_count_sum=sum([t.user_follower_count for t in tweet_info])\n",
    "    for i in range(len(group)):\n",
    "        sumvec+=group[i]*((tweet_info[i].user_follower_count+1)/(retweet_count_sum+len(group)))\n",
    "    return sumvec\n",
    "\n",
    "def convert2single(dataset,tweet_info_corp):\n",
    "    return [group2single(dataset[i],tweet_info_corp[i]) for i in range(len(dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainX=convert2single(train_tweet_grp_vectors,train_tweet_info)\n",
    "TestX=convert2single(test_tweet_grp_vectors,test_tweet_info)\n",
    "DevX=convert2single(dev_tweet_grp_vectors,dev_tweet_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat =y_hat = np.where(y_hat < 0.5, 0, 1)  \n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\":\"lgb_f1_score\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.01, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.01, 10.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 300),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.1, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.1, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 300),\n",
    "        \"learning_rate\":trial.suggest_float(\"learning_rate\", 0.001, 0.5),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 100, 500),\n",
    "        'num_iterations': trial.suggest_int('num_iterations', 400, 800),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 160000,160000),\n",
    "        'min_data_per_group':trial.suggest_int('min_data_per_group', 100,500)\n",
    "    }\n",
    "    \n",
    "    model=lgb.LGBMClassifier()\n",
    "    model=model.set_params(**param)\n",
    "    model=model.fit(TrainX,TrainY)\n",
    "    pred=model.predict(DevX)\n",
    "    f1 = f1_score(DevY,pred)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "param=study.best_trial.params\n",
    "param['metric']=\"lgb_f1_score\"\n",
    "param[\"objective\"]= \"binary\"\n",
    "param[\"verbosity\"]= -1\n",
    "param[\"boosting_type\"]=\"gbdt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=lgb.LGBMClassifier()\n",
    "model=model.set_params(**param)\n",
    "model=model.fit(TrainX,TrainY)\n",
    "pred=model.predict(DevX)\n",
    "print_scores(DevY,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model,'lgb_200glove_usrfollcnt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(Counter(TrainY))\n",
    "print(Counter(DevY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(TrainY))\n",
    "print(len(DevY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(TestX))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
